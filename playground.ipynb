{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8bef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data_pipelines.external.util import APIHttpClient, ClientsBaseURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf0696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://opendata.dwd.de/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClientsBaseURLs.dwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74eb5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = APIHttpClient(ClientsBaseURLs.dwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f01e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = getter.get(endpoint=\"weather/local_forecasts/mos/MOSMIX_L/single_stations/01001/kml/MOSMIX_L_LATEST_01001.kmz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08d94c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f77a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "class DWDMosmixLSingleStationKMZParser:\n",
    "    \"\"\"Parser for DWD MOSMIX-L single station KMZ forecasts with raw data preservation.\"\"\"\n",
    "    \n",
    "    # XML namespaces\n",
    "    NS = {\n",
    "        \"kml\": \"http://www.opengis.net/kml/2.2\",\n",
    "        \"dwd\": \"https://opendata.dwd.de/weather/lib/pointforecast_dwd_extension_V1_0.xsd\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, kmz_content: bytes):\n",
    "        \"\"\"\n",
    "        Initialize parser with KMZ binary content.\n",
    "        \n",
    "        Args:\n",
    "            kmz_content: Binary content of the KMZ file from HTTP response\n",
    "        \"\"\"\n",
    "        self.kmz_content = kmz_content\n",
    "        self.issue_time: Optional[str] = None  # Keep as raw string\n",
    "        self.timestamps: List[str] = []        # Keep as raw strings\n",
    "        self.forecasts: List[Dict[str, Any]] = []\n",
    "        \n",
    "        # Parse content on initialization\n",
    "        self._parse()\n",
    "    \n",
    "    def _extract_kml(self) -> str:\n",
    "        \"\"\"Extract KML content from KMZ archive.\"\"\"\n",
    "        with io.BytesIO(self.kmz_content) as bio:\n",
    "            with zipfile.ZipFile(bio) as kmz:\n",
    "                if not kmz.filelist:\n",
    "                    raise ValueError(\"Empty KMZ archive\")\n",
    "                with kmz.open(kmz.filelist[0]) as kml_file:\n",
    "                    return kml_file.read().decode(\"ISO-8859-1\")\n",
    "    \n",
    "    def _parse(self):\n",
    "        \"\"\"Main parsing method preserving raw data values.\"\"\"\n",
    "        kml_content = self._extract_kml()\n",
    "        root = ET.fromstring(kml_content)\n",
    "        \n",
    "        # Parse issue time (keep as raw string)\n",
    "        issue_time_elem = root.find(\".//dwd:IssueTime\", self.NS)\n",
    "        if issue_time_elem is not None and issue_time_elem.text:\n",
    "            self.issue_time = issue_time_elem.text.strip()\n",
    "        \n",
    "        # Parse forecast timestamps (keep as raw strings)\n",
    "        timesteps_elem = root.find(\".//dwd:ForecastTimeSteps\", self.NS)\n",
    "        if timesteps_elem is not None:\n",
    "            for ts_elem in timesteps_elem.findall(\"dwd:TimeStep\", self.NS):\n",
    "                if ts_elem.text:\n",
    "                    self.timestamps.append(ts_elem.text.strip())\n",
    "        \n",
    "        # Parse forecasts from the first Placemark\n",
    "        placemark = root.find(\".//kml:Placemark\", self.NS)\n",
    "        if placemark is not None:\n",
    "            self._parse_forecasts(placemark)\n",
    "    \n",
    "    def _parse_forecasts(self, placemark: ET.Element):\n",
    "        \"\"\"Parse forecast data preserving raw values.\"\"\"\n",
    "        # Prepare empty forecasts structure\n",
    "        forecast_data = [{\"timestamp\": ts} for ts in self.timestamps]\n",
    "        \n",
    "        # Process each forecast parameter\n",
    "        for forecast_elem in placemark.findall(\".//dwd:Forecast\", self.NS):\n",
    "            # Get parameter name\n",
    "            param_name = forecast_elem.attrib.get(f\"{{{self.NS['dwd']}}}elementName\")\n",
    "            if param_name not in (\"RR1c\", \"RR3c\"):\n",
    "                continue\n",
    "            \n",
    "            # Get values string\n",
    "            value_elem = forecast_elem.find(\"dwd:value\", self.NS)\n",
    "            if value_elem is None or value_elem.text is None:\n",
    "                continue\n",
    "                \n",
    "            # Split values and keep as raw strings\n",
    "            values = [v.strip() for v in value_elem.text.split()]\n",
    "            \n",
    "            # Assign values to timestamps\n",
    "            for i in range(min(len(forecast_data), len(values))):\n",
    "                forecast_data[i][param_name] = values[i]\n",
    "        \n",
    "        self.forecasts = forecast_data\n",
    "    \n",
    "    def get_issue_time(self) -> Optional[str]:\n",
    "        \"\"\"Get raw issue time string.\"\"\"\n",
    "        return self.issue_time\n",
    "    \n",
    "    def get_timestamps(self) -> List[str]:\n",
    "        \"\"\"Get raw timestamp strings.\"\"\"\n",
    "        return self.timestamps\n",
    "    \n",
    "    def get_forecasts(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get forecasts with raw values.\n",
    "        \n",
    "        Returns:\n",
    "            List of forecast entries with timestamp and parameter values\n",
    "        \"\"\"\n",
    "        return self.forecasts\n",
    "    \n",
    "    def to_json(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert parsed data to JSON-serializable dictionary with raw values.\"\"\"\n",
    "        return {\n",
    "            \"issue_time\": self.issue_time,\n",
    "            \"forecasts\": self.forecasts\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bab2e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DWDMosmixLSingleStationKMZParser(response.content)\n",
    "\n",
    "# Parse content with raw values\n",
    "parser = DWDMosmixLSingleStationKMZParser(response.content)\n",
    "\n",
    "# Access raw data\n",
    "issue_time = parser.get_issue_time()  # \"2023-06-15T10:00:00.000Z\"\n",
    "timestamps = parser.get_timestamps()  # [\"2023-06-15T12:00:00.000Z\", ...]\n",
    "forecasts = parser.get_forecasts()    # List of raw forecast dictionaries\n",
    "\n",
    "# Get JSON representation\n",
    "json_data = parser.to_json()  # Contains all raw values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "766c0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issue_time': '2025-07-15T09:00:00.000Z',\n",
       " 'forecasts': [{'timestamp': '2025-07-15T10:00:00.000Z',\n",
       "   'RR1c': '0.00',\n",
       "   'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-15T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-15T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-15T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-15T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-15T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T01:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T02:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T03:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-16T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-16T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-17T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-17T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-18T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-18T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-19T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-19T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-20T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-20T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T06:00:00.000Z', 'RR1c': '0.90', 'RR3c': '0.90'},\n",
       "  {'timestamp': '2025-07-20T07:00:00.000Z', 'RR1c': '0.40', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T08:00:00.000Z', 'RR1c': '0.40', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.70'},\n",
       "  {'timestamp': '2025-07-20T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-20T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.40'},\n",
       "  {'timestamp': '2025-07-20T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-20T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-20T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-20T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-21T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-21T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T05:00:00.000Z', 'RR1c': '0.60', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T06:00:00.000Z', 'RR1c': '0.70', 'RR3c': '1.40'},\n",
       "  {'timestamp': '2025-07-21T07:00:00.000Z', 'RR1c': '0.40', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T08:00:00.000Z', 'RR1c': '0.40', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T09:00:00.000Z', 'RR1c': '0.40', 'RR3c': '1.20'},\n",
       "  {'timestamp': '2025-07-21T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-21T13:00:00.000Z', 'RR1c': '0.80', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.80'},\n",
       "  {'timestamp': '2025-07-21T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-21T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-21T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-21T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T06:00:00.000Z', 'RR1c': '1.90', 'RR3c': '1.90'},\n",
       "  {'timestamp': '2025-07-22T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.50'},\n",
       "  {'timestamp': '2025-07-22T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-22T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-22T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-23T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-23T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '1.00'},\n",
       "  {'timestamp': '2025-07-23T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.80'},\n",
       "  {'timestamp': '2025-07-23T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-23T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.50'},\n",
       "  {'timestamp': '2025-07-23T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-23T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-23T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-23T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-24T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-24T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.90'},\n",
       "  {'timestamp': '2025-07-24T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.60'},\n",
       "  {'timestamp': '2025-07-24T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-24T13:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T14:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T15:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.40'},\n",
       "  {'timestamp': '2025-07-24T16:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T17:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T18:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-24T19:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T20:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T21:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-24T22:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-24T23:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T00:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-25T01:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T02:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T03:00:00.000Z', 'RR1c': '-', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-25T04:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T05:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T06:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.30'},\n",
       "  {'timestamp': '2025-07-25T07:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T08:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T09:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-25T10:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T11:00:00.000Z', 'RR1c': '0.00', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T12:00:00.000Z', 'RR1c': '0.00', 'RR3c': '0.00'},\n",
       "  {'timestamp': '2025-07-25T13:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T14:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T15:00:00.000Z', 'RR1c': '-', 'RR3c': '-'},\n",
       "  {'timestamp': '2025-07-25T16:00:00.000Z', 'RR1c': '-', 'RR3c': '-'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e1481b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example usage:\n",
      "1. Initialize parser:\n",
      "   parser = DwdMosmixNotebook('path/to/your/file.kmz')\n",
      "\n",
      "2. Get timestamps:\n",
      "   timestamps = parser.get_timestamps_readable()\n",
      "   print(f'Found {len(timestamps)} forecast timestamps')\n",
      "\n",
      "3. Get stations:\n",
      "   stations = parser.get_stations()\n",
      "   print(f'Found {len(stations)} weather stations')\n",
      "\n",
      "4. Get forecasts for specific stations:\n",
      "   forecasts = parser.get_forecasts(['station_id_1', 'station_id_2'])\n",
      "\n",
      "5. Find nearby stations:\n",
      "   nearby = parser.get_stations_near(52.52, 13.41, max_distance_km=100)\n",
      "\n",
      "6. Save data to JSON:\n",
      "   parser.save_to_json(stations, 'stations.json')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "DWD MOSMIX Parser for Jupyter Notebook\n",
    "Adapted from the original command-line version for interactive use\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "from locale import setlocale, LC_ALL\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional, List, IO, Tuple, Dict, Generator, ClassVar, Set, Iterator, Any, Iterable, Union, Literal\n",
    "\n",
    "try:\n",
    "    from lxml.etree import iterparse, _Element as Element\n",
    "except ModuleNotFoundError:\n",
    "    from xml.etree.ElementTree import iterparse, Element  # type: ignore[assignment]\n",
    "\n",
    "\n",
    "class TimezoneFinder:\n",
    "    def timezone_at(self, **kwargs) -> Optional[str]:\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    def get_inst(cls, enabled: bool) -> \"TimezoneFinder\":\n",
    "        if not enabled:\n",
    "            return cls()\n",
    "        try:\n",
    "            from timezonefinder import TimezoneFinder as TF  # import only when needed at runtime due to overhead\n",
    "            return TF(in_memory=True)  # type: ignore\n",
    "        except ModuleNotFoundError:\n",
    "            return cls()\n",
    "\n",
    "\n",
    "class DwdMosmixParser:\n",
    "    \"\"\"\n",
    "    Parsing methods for DWD MOSMIX KML XML files, namely either:\n",
    "      * list of timestamps from ``ForecastTimeSteps``\n",
    "      * properties of stations in ``Placemark``\n",
    "      * value series in ``Forecast``\n",
    "    Note that all methods iteratively consume from an i/o stream, such that it cannot be reused without rewinding it.\n",
    "    \"\"\"\n",
    "\n",
    "    _ns: ClassVar[Dict[str, str]] = {  # abbreviations for used XML namespaces for readability\n",
    "        \"kml\": r\"http://www.opengis.net/kml/2.2\",\n",
    "        \"dwd\": r\"https://opendata.dwd.de/weather/lib/pointforecast_dwd_extension_V1_0.xsd\",\n",
    "    }\n",
    "    _undef_sign: ClassVar[str] = \"-\"  # dwd:FormatCfg/dwd:DefaultUndefSign\n",
    "\n",
    "    @classmethod\n",
    "    def _iter_tag(cls, fp: IO[bytes], tag: str) -> Iterator[Element]:\n",
    "        if \":\" in tag:\n",
    "            ns, tag = tag.split(\":\", maxsplit=1)\n",
    "            tag = f\"{{{cls._ns[ns]}}}{tag}\"\n",
    "        for _evt, elem in iterparse(fp, events=[\"end\"]):  # type: str, Element\n",
    "            if elem.tag == tag:\n",
    "                yield elem\n",
    "                elem.clear()\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_timestamp(cls, value: Optional[str]) -> int:\n",
    "        if not value:\n",
    "            raise ValueError(\"Undefined timestamp\")\n",
    "        try:\n",
    "            return int(datetime.strptime(value, \"%Y-%m-%dT%H:%M:%S.000Z\").replace(tzinfo=timezone.utc).timestamp())\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Cannot parse timestamp '{value}'\") from e\n",
    "\n",
    "    def parse_timestamps(self, fp: IO[bytes]) -> Iterator[int]:\n",
    "        \"\"\"Give all ``ForecastTimeSteps`` as integer timestamps.\"\"\"\n",
    "        for elem in self._iter_tag(fp, \"dwd:ForecastTimeSteps\"):\n",
    "            yield from (self._parse_timestamp(_.text) for _ in elem.iterfind(\"dwd:TimeStep\", self._ns))\n",
    "            break\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_coordinates(cls, value: str) -> Tuple[float, float, float]:\n",
    "        values: List[str] = value.split(\",\")\n",
    "        if len(values) != 3:\n",
    "            raise ValueError(f\"Cannot parse coordinates '{value}'\")\n",
    "        try:\n",
    "            return float(values[0]), float(values[1]), float(values[2])\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Cannot parse coordinates '{value}'\") from e\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_description(cls, placemark: Element) -> str:\n",
    "        description: Optional[Element] = placemark.find(\"kml:description\", cls._ns)\n",
    "        if description is None or not description.text:\n",
    "            raise ValueError(\"No 'Placemark.description' found\")\n",
    "        return description.text\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_placemark(cls, placemark: Element) -> Dict[str, Any]:\n",
    "        name: Optional[Element] = placemark.find(\"kml:name\", cls._ns)\n",
    "        if name is None or not name.text:\n",
    "            raise ValueError(\"No 'Placemark.name' found\")\n",
    "\n",
    "        coordinates: Optional[Element] = placemark.find(\"kml:Point/kml:coordinates\", cls._ns)\n",
    "        if coordinates is None or not coordinates.text:\n",
    "            raise ValueError(\"No 'Placemark.Point.coordinates' found\")\n",
    "        lng, lat, ele = cls._parse_coordinates(coordinates.text)\n",
    "\n",
    "        return {\n",
    "            \"desc\": cls._parse_description(placemark),\n",
    "            \"name\": name.text,\n",
    "            \"lat\": lat,\n",
    "            \"lng\": lng,\n",
    "            \"ele\": ele,\n",
    "        }\n",
    "\n",
    "    def parse_placemarks(self, fp: IO[bytes], timezones: bool) -> Iterator[Dict[str, Any]]:\n",
    "        \"\"\"Give all stations with their properties from ``Placemark`` nodes.\"\"\"\n",
    "        tf: TimezoneFinder = TimezoneFinder.get_inst(timezones)\n",
    "        for elem in self._iter_tag(fp, \"kml:Placemark\"):\n",
    "            placemark: Dict[str, Any] = self._parse_placemark(elem)\n",
    "            placemark[\"tz\"] = tf.timezone_at(lng=placemark[\"lng\"], lat=placemark[\"lat\"])\n",
    "            yield placemark\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_values(cls, values: str) -> List[Optional[float]]:\n",
    "        try:\n",
    "            return [float(_) if _ != cls._undef_sign else None for _ in values.split()]\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Cannot parse forecast values '{values}'\") from e\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_forecast(cls, placemark: Element) -> Dict[str, List[Optional[float]]]:\n",
    "        forecasts: Dict[str, List[Optional[float]]] = {}\n",
    "        for forecast in placemark.iterfind(\"kml:ExtendedData/dwd:Forecast\", cls._ns):\n",
    "            name: Optional[Union[str, bytes]] = forecast.attrib.get(f\"{{{cls._ns['dwd']}}}elementName\")\n",
    "            if not isinstance(name, str) or not name:\n",
    "                raise ValueError(\"No 'Forecast.elementName' found\")\n",
    "\n",
    "            value: Optional[Element] = forecast.find(\"dwd:value\", cls._ns)\n",
    "            if value is None or not value.text:\n",
    "                raise ValueError(\"No 'Forecast.value' found\")\n",
    "\n",
    "            forecasts[name] = cls._parse_values(value.text)\n",
    "        return forecasts\n",
    "\n",
    "    def parse_forecasts(self, fp: IO[bytes],\n",
    "                        stations: Optional[Set[str]]) -> Iterator[Tuple[str, Dict[str, List[Optional[float]]]]]:\n",
    "        \"\"\"Give all value series in ``Forecast``, optionally limited to certain stations.\"\"\"\n",
    "        for elem in self._iter_tag(fp, \"kml:Placemark\"):\n",
    "            station: str = self._parse_description(elem)\n",
    "            if stations is None or station in stations:\n",
    "                yield station, self._parse_forecast(elem)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def kmz_reader(fp: IO[bytes]) -> Generator[IO[bytes], None, None]:\n",
    "    \"\"\"\n",
    "    Wrap reading from *.kmz files, which are merely compressed *.kml (XML) files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with ZipFile(fp) as zf:\n",
    "            if len(zf.filelist) != 1:\n",
    "                raise OSError(f\"Unexpected archive contents: {' '.join(zf.namelist())}\")\n",
    "            with zf.open(zf.filelist[0]) as zp:\n",
    "                yield zp\n",
    "    except BadZipFile as e:\n",
    "        raise OSError(str(e)) from None\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def kml_reader(filename: Path, compressed: Optional[bool] = None) -> Generator[IO[bytes], None, None]:\n",
    "    \"\"\"\n",
    "    Read access for *.kml or compressed *.kmz files.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        if compressed is True or (compressed is None and filename.suffix == \".kmz\"):\n",
    "            with kmz_reader(fp) as zp:\n",
    "                yield zp\n",
    "        else:\n",
    "            yield fp\n",
    "\n",
    "\n",
    "# Jupyter-friendly wrapper functions\n",
    "class DwdMosmixNotebook:\n",
    "    \"\"\"\n",
    "    Jupyter notebook-friendly wrapper for DWD MOSMIX parser\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize with path to KMZ/KML file\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the MOSMIX KMZ or KML file\n",
    "        \"\"\"\n",
    "        self.file_path = Path(file_path)\n",
    "        self.parser = DwdMosmixParser()\n",
    "        setlocale(LC_ALL, \"C\")  # for strptime\n",
    "        \n",
    "    def get_timestamps(self) -> List[int]:\n",
    "        \"\"\"\n",
    "        Parse and return all forecast timestamps as Unix timestamps\n",
    "        \n",
    "        Returns:\n",
    "            List of Unix timestamps\n",
    "        \"\"\"\n",
    "        with kml_reader(self.file_path) as fp:\n",
    "            return list(self.parser.parse_timestamps(fp))\n",
    "    \n",
    "    def get_timestamps_readable(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Parse and return all forecast timestamps in human-readable format\n",
    "        \n",
    "        Returns:\n",
    "            List of timestamp strings in ISO format\n",
    "        \"\"\"\n",
    "        timestamps = self.get_timestamps()\n",
    "        return [datetime.fromtimestamp(ts, tz=timezone.utc).isoformat() for ts in timestamps]\n",
    "    \n",
    "    def get_stations(self, include_timezones: bool = False) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse and return all weather stations information\n",
    "        \n",
    "        Args:\n",
    "            include_timezones: Whether to determine timezones from coordinates\n",
    "            \n",
    "        Returns:\n",
    "            List of station dictionaries with keys: desc, name, lat, lng, ele, tz\n",
    "        \"\"\"\n",
    "        with kml_reader(self.file_path) as fp:\n",
    "            return list(self.parser.parse_placemarks(fp, include_timezones))\n",
    "    \n",
    "    def get_forecasts(self, station_ids: Optional[List[str]] = None) -> Dict[str, Dict[str, List[Optional[float]]]]:\n",
    "        \"\"\"\n",
    "        Parse and return forecast data for all or specified stations\n",
    "        \n",
    "        Args:\n",
    "            station_ids: Optional list of station IDs to limit results to\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping station IDs to their forecast data\n",
    "        \"\"\"\n",
    "        stations_set = set(station_ids) if station_ids else None\n",
    "        with kml_reader(self.file_path) as fp:\n",
    "            return dict(self.parser.parse_forecasts(fp, stations_set))\n",
    "    \n",
    "    def save_to_json(self, data: Any, output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save data to JSON file\n",
    "        \n",
    "        Args:\n",
    "            data: Data to save\n",
    "            output_path: Path to output JSON file\n",
    "        \"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def get_station_by_name(self, name: str, include_timezones: bool = False) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Find a station by name\n",
    "        \n",
    "        Args:\n",
    "            name: Station name to search for\n",
    "            include_timezones: Whether to determine timezones from coordinates\n",
    "            \n",
    "        Returns:\n",
    "            Station dictionary or None if not found\n",
    "        \"\"\"\n",
    "        stations = self.get_stations(include_timezones)\n",
    "        for station in stations:\n",
    "            if name.lower() in station['name'].lower():\n",
    "                return station\n",
    "        return None\n",
    "    \n",
    "    def get_stations_near(self, lat: float, lng: float, max_distance_km: float = 50.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Find stations within a certain distance of given coordinates\n",
    "        \n",
    "        Args:\n",
    "            lat: Latitude\n",
    "            lng: Longitude\n",
    "            max_distance_km: Maximum distance in kilometers\n",
    "            \n",
    "        Returns:\n",
    "            List of stations within the specified distance\n",
    "        \"\"\"\n",
    "        import math\n",
    "        \n",
    "        def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "            \"\"\"Calculate the great circle distance between two points on Earth\"\"\"\n",
    "            R = 6371  # Earth's radius in km\n",
    "            \n",
    "            lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "            c = 2 * math.asin(math.sqrt(a))\n",
    "            \n",
    "            return R * c\n",
    "        \n",
    "        stations = self.get_stations()\n",
    "        nearby_stations = []\n",
    "        \n",
    "        for station in stations:\n",
    "            distance = haversine_distance(lat, lng, station['lat'], station['lng'])\n",
    "            if distance <= max_distance_km:\n",
    "                station['distance_km'] = round(distance, 2)\n",
    "                nearby_stations.append(station)\n",
    "        \n",
    "        # Sort by distance\n",
    "        nearby_stations.sort(key=lambda x: x['distance_km'])\n",
    "        return nearby_stations\n",
    "\n",
    "\n",
    "# Example usage functions for the notebook\n",
    "def example_usage():\n",
    "    \"\"\"\n",
    "    Example usage of the DWD MOSMIX parser in Jupyter notebook\n",
    "    \"\"\"\n",
    "    print(\"Example usage:\")\n",
    "    print(\"1. Initialize parser:\")\n",
    "    print(\"   parser = DwdMosmixNotebook('path/to/your/file.kmz')\")\n",
    "    print()\n",
    "    print(\"2. Get timestamps:\")\n",
    "    print(\"   timestamps = parser.get_timestamps_readable()\")\n",
    "    print(\"   print(f'Found {len(timestamps)} forecast timestamps')\")\n",
    "    print()\n",
    "    print(\"3. Get stations:\")\n",
    "    print(\"   stations = parser.get_stations()\")\n",
    "    print(\"   print(f'Found {len(stations)} weather stations')\")\n",
    "    print()\n",
    "    print(\"4. Get forecasts for specific stations:\")\n",
    "    print(\"   forecasts = parser.get_forecasts(['station_id_1', 'station_id_2'])\")\n",
    "    print()\n",
    "    print(\"5. Find nearby stations:\")\n",
    "    print(\"   nearby = parser.get_stations_near(52.52, 13.41, max_distance_km=100)\")\n",
    "    print()\n",
    "    print(\"6. Save data to JSON:\")\n",
    "    print(\"   parser.save_to_json(stations, 'stations.json')\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6419f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DWD MOSMIX Parser Example ===\n",
      "✓ Successfully initialized parser with file: MOSMIX_L_LATEST_01001(1).kmz\n",
      "\n",
      "=== Getting Forecast Timestamps ===\n",
      "Found 247 forecast timestamps\n",
      "First 5 timestamps:\n",
      "  1. 2025-07-15T04:00:00+00:00\n",
      "  2. 2025-07-15T05:00:00+00:00\n",
      "  3. 2025-07-15T06:00:00+00:00\n",
      "  4. 2025-07-15T07:00:00+00:00\n",
      "  5. 2025-07-15T08:00:00+00:00\n",
      "  ... and 242 more\n",
      "\n",
      "=== Getting Weather Stations ===\n",
      "Found 1 weather stations\n",
      "\n",
      "First 3 stations:\n",
      "  1. 01001 (JAN MAYEN)\n",
      "     Location: 70.9300°N, -8.6700°E\n",
      "     Elevation: 10m\n",
      "     Timezone: Europe/Oslo\n",
      "\n",
      "\n",
      "=== Converting Stations to DataFrame ===\n",
      "DataFrame shape: (1, 6)\n",
      "\n",
      "Column names: ['desc', 'name', 'lat', 'lng', 'ele', 'tz']\n",
      "\n",
      "First few rows:\n",
      "        desc   name    lat   lng   ele           tz\n",
      "0  JAN MAYEN  01001  70.93 -8.67  10.0  Europe/Oslo\n",
      "\n",
      "Latitude range: 70.93° to 70.93°\n",
      "Longitude range: -8.67° to -8.67°\n",
      "Elevation range: 10m to 10m\n",
      "\n",
      "=== Finding Stations by Name ===\n",
      "No Berlin station found\n",
      "No Munich station found\n",
      "\n",
      "=== Finding Nearby Stations ===\n",
      "Found 0 stations within 100km of Berlin\n",
      "\n",
      "Closest 5 stations to Berlin:\n",
      "\n",
      "=== Getting Forecast Data ===\n",
      "Retrieved forecasts for 1 stations\n",
      "\n",
      "Forecast parameters for station JAN MAYEN:\n",
      "  PPPP: 247 values (247 non-null)\n",
      "    Range: 101000.00 to 102280.00\n",
      "  E_PPP: 247 values (247 non-null)\n",
      "    Range: 10.00 to 620.00\n",
      "  TX: 247 values (23 non-null)\n",
      "    Range: 281.15 to 286.75\n",
      "  TTT: 247 values (247 non-null)\n",
      "    Range: 280.15 to 285.65\n",
      "  E_TTT: 247 values (247 non-null)\n",
      "    Range: 0.60 to 1.90\n",
      "  Td: 247 values (247 non-null)\n",
      "    Range: 277.95 to 281.85\n",
      "  E_Td: 247 values (247 non-null)\n",
      "    Range: 0.50 to 1.90\n",
      "  TN: 247 values (23 non-null)\n",
      "    Range: 279.25 to 283.05\n",
      "  TG: 247 values (0 non-null)\n",
      "  TM: 247 values (11 non-null)\n",
      "    Range: 280.45 to 284.25\n",
      "  T5cm: 247 values (0 non-null)\n",
      "  DD: 247 values (247 non-null)\n",
      "    Range: 66.00 to 360.00\n",
      "  E_DD: 247 values (247 non-null)\n",
      "    Range: 19.00 to 99.00\n",
      "  FF: 247 values (247 non-null)\n",
      "    Range: 1.54 to 5.14\n",
      "  E_FF: 247 values (247 non-null)\n",
      "    Range: 0.51 to 3.09\n",
      "  FX1: 247 values (0 non-null)\n",
      "  FX3: 247 values (0 non-null)\n",
      "  FX625: 247 values (0 non-null)\n",
      "  FX640: 247 values (0 non-null)\n",
      "  FX655: 247 values (0 non-null)\n",
      "  FXh: 247 values (0 non-null)\n",
      "  FXh25: 247 values (0 non-null)\n",
      "  FXh40: 247 values (0 non-null)\n",
      "  FXh55: 247 values (0 non-null)\n",
      "  N: 247 values (228 non-null)\n",
      "    Range: 37.00 to 100.00\n",
      "  Neff: 247 values (208 non-null)\n",
      "    Range: 47.00 to 99.00\n",
      "  Nlm: 247 values (208 non-null)\n",
      "    Range: 45.00 to 99.00\n",
      "  Nh: 247 values (206 non-null)\n",
      "    Range: 0.00 to 100.00\n",
      "  Nm: 247 values (206 non-null)\n",
      "    Range: 0.00 to 97.00\n",
      "  Nl: 247 values (228 non-null)\n",
      "    Range: 28.00 to 94.00\n",
      "  N05: 247 values (208 non-null)\n",
      "    Range: 3.00 to 88.00\n",
      "  VV: 247 values (206 non-null)\n",
      "    Range: 900.00 to 22900.00\n",
      "  VV10: 247 values (208 non-null)\n",
      "    Range: 4.00 to 64.00\n",
      "  wwM: 247 values (208 non-null)\n",
      "    Range: 2.00 to 51.00\n",
      "  wwM6: 247 values (246 non-null)\n",
      "    Range: 3.00 to 85.00\n",
      "  wwMh: 247 values (41 non-null)\n",
      "    Range: 24.00 to 88.00\n",
      "  wwMd: 247 values (20 non-null)\n",
      "    Range: 30.00 to 94.00\n",
      "  ww: 247 values (246 non-null)\n",
      "    Range: 1.00 to 45.00\n",
      "  ww3: 247 values (82 non-null)\n",
      "    Range: 1.00 to 61.00\n",
      "  W1W2: 247 values (41 non-null)\n",
      "    Range: 10.00 to 65.00\n",
      "  wwP: 247 values (208 non-null)\n",
      "    Range: 2.00 to 40.00\n",
      "  wwP6: 247 values (246 non-null)\n",
      "    Range: 4.00 to 78.00\n",
      "  wwPh: 247 values (41 non-null)\n",
      "    Range: 16.00 to 81.00\n",
      "  wwPd: 247 values (20 non-null)\n",
      "    Range: 25.00 to 94.00\n",
      "  wwZ: 247 values (208 non-null)\n",
      "    Range: 1.00 to 31.00\n",
      "  wwZ6: 247 values (246 non-null)\n",
      "    Range: 3.00 to 70.00\n",
      "  wwZh: 247 values (41 non-null)\n",
      "    Range: 11.00 to 76.00\n",
      "  wwD: 247 values (208 non-null)\n",
      "    Range: 1.00 to 40.00\n",
      "  wwD6: 247 values (246 non-null)\n",
      "    Range: 4.00 to 76.00\n",
      "  wwDh: 247 values (41 non-null)\n",
      "    Range: 16.00 to 81.00\n",
      "  wwC: 247 values (208 non-null)\n",
      "    Range: 0.00 to 3.00\n",
      "  wwC6: 247 values (246 non-null)\n",
      "    Range: 0.00 to 5.00\n",
      "  wwCh: 247 values (41 non-null)\n",
      "    Range: 1.00 to 5.00\n",
      "  wwT: 247 values (94 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwT6: 247 values (80 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwTh: 247 values (41 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwTd: 247 values (20 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwS: 247 values (208 non-null)\n",
      "    Range: 0.00 to 1.00\n",
      "  wwS6: 247 values (246 non-null)\n",
      "    Range: 0.00 to 1.00\n",
      "  wwSh: 247 values (41 non-null)\n",
      "    Range: 0.00 to 1.00\n",
      "  wwL: 247 values (208 non-null)\n",
      "    Range: 2.00 to 40.00\n",
      "  wwL6: 247 values (246 non-null)\n",
      "    Range: 4.00 to 81.00\n",
      "  wwLh: 247 values (41 non-null)\n",
      "    Range: 16.00 to 80.00\n",
      "  wwF: 247 values (206 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwF6: 247 values (246 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  wwFh: 247 values (41 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  DRR1: 247 values (0 non-null)\n",
      "  RR6c: 247 values (41 non-null)\n",
      "    Range: 0.00 to 1.40\n",
      "  RRhc: 247 values (21 non-null)\n",
      "    Range: 0.00 to 1.40\n",
      "  RRdc: 247 values (11 non-null)\n",
      "    Range: 0.00 to 2.60\n",
      "  RR1c: 247 values (183 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  RRS1c: 247 values (183 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  RRL1c: 247 values (183 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  RR3c: 247 values (81 non-null)\n",
      "    Range: 0.00 to 1.40\n",
      "  RRS3c: 247 values (81 non-null)\n",
      "    Range: 0.00 to 0.00\n",
      "  R101: 247 values (0 non-null)\n",
      "  R102: 247 values (0 non-null)\n",
      "  R103: 247 values (0 non-null)\n",
      "  R105: 247 values (0 non-null)\n",
      "  R107: 247 values (0 non-null)\n",
      "  R110: 247 values (0 non-null)\n",
      "  R120: 247 values (0 non-null)\n",
      "  R130: 247 values (0 non-null)\n",
      "  R150: 247 values (0 non-null)\n",
      "  RR1o1: 247 values (0 non-null)\n",
      "  RR1w1: 247 values (0 non-null)\n",
      "  RR1u1: 247 values (0 non-null)\n",
      "  R600: 247 values (41 non-null)\n",
      "    Range: 5.00 to 62.00\n",
      "  R602: 247 values (41 non-null)\n",
      "    Range: 1.00 to 40.00\n",
      "  R610: 247 values (41 non-null)\n",
      "    Range: 0.00 to 20.00\n",
      "  R650: 247 values (41 non-null)\n",
      "    Range: 0.00 to 7.00\n",
      "  Rh00: 247 values (21 non-null)\n",
      "    Range: 11.00 to 65.00\n",
      "  Rh02: 247 values (21 non-null)\n",
      "    Range: 4.00 to 49.00\n",
      "  Rh10: 247 values (21 non-null)\n",
      "    Range: 1.00 to 28.00\n",
      "  Rh50: 247 values (21 non-null)\n",
      "    Range: 0.00 to 7.00\n",
      "  Rd00: 247 values (11 non-null)\n",
      "    Range: 14.00 to 77.00\n",
      "  Rd02: 247 values (11 non-null)\n",
      "    Range: 12.00 to 65.00\n",
      "  Rd10: 247 values (11 non-null)\n",
      "    Range: 3.00 to 40.00\n",
      "  Rd50: 247 values (11 non-null)\n",
      "    Range: 0.00 to 20.00\n",
      "  SunD: 247 values (0 non-null)\n",
      "  RSunD: 247 values (0 non-null)\n",
      "  PSd00: 247 values (0 non-null)\n",
      "  PSd30: 247 values (0 non-null)\n",
      "  PSd60: 247 values (0 non-null)\n",
      "  RRad1: 247 values (137 non-null)\n",
      "    Range: 14.00 to 66.00\n",
      "  Rad1h: 247 values (137 non-null)\n",
      "    Range: 180.00 to 2110.00\n",
      "  SunD1: 247 values (0 non-null)\n",
      "  SunD3: 247 values (0 non-null)\n",
      "  PEvap: 247 values (7 non-null)\n",
      "    Range: 3.40 to 21.50\n",
      "  WPc11: 247 values (246 non-null)\n",
      "    Range: 1.00 to 61.00\n",
      "  WPc31: 247 values (82 non-null)\n",
      "    Range: 1.00 to 61.00\n",
      "  WPc61: 247 values (82 non-null)\n",
      "    Range: 1.00 to 61.00\n",
      "  WPch1: 247 values (40 non-null)\n",
      "    Range: 1.00 to 61.00\n",
      "  WPcd1: 247 values (19 non-null)\n",
      "    Range: 1.00 to 51.00\n",
      "\n",
      "=== Creating Forecast DataFrame for JAN MAYEN ===\n",
      "Created DataFrame with 247 rows and 115 columns\n",
      "\n",
      "First few rows:\n",
      "                   timestamp      PPPP  E_PPP      TX     TTT  E_TTT      Td  \\\n",
      "0  2025-07-15T04:00:00+00:00  102210.0   10.0  282.25  281.95    0.7  280.65   \n",
      "1  2025-07-15T05:00:00+00:00  102190.0   20.0  283.45  282.65    0.9  280.95   \n",
      "2  2025-07-15T06:00:00+00:00  102190.0   20.0  284.55  283.35    1.2  280.95   \n",
      "3  2025-07-15T07:00:00+00:00  102200.0   20.0     NaN  283.95    1.4  281.05   \n",
      "4  2025-07-15T08:00:00+00:00  102200.0   30.0     NaN  284.45    1.5  281.05   \n",
      "\n",
      "   E_Td      TN    TG  ...  RRad1   Rad1h  SunD1  SunD3  PEvap  WPc11 WPc31  \\\n",
      "0   0.8  280.85  None  ...   25.0   180.0   None   None    NaN   45.0   NaN   \n",
      "1   1.5  280.85  None  ...   36.0   370.0   None   None    NaN    1.0   NaN   \n",
      "2   1.3  280.75  None  ...   46.0   640.0   None   None    NaN    1.0  45.0   \n",
      "3   1.7     NaN  None  ...   57.0  1000.0   None   None    NaN   45.0   NaN   \n",
      "4   1.9     NaN  None  ...   59.0  1260.0   None   None    NaN    1.0   NaN   \n",
      "\n",
      "  WPc61 WPch1 WPcd1  \n",
      "0   NaN   NaN   NaN  \n",
      "1   NaN   NaN   NaN  \n",
      "2  45.0   NaN   NaN  \n",
      "3   NaN   NaN   NaN  \n",
      "4   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 115 columns]\n",
      "\n",
      "=== Saving Data to Files ===\n",
      "✓ Saved stations to 'stations.json'\n",
      "✓ Saved timestamps to 'timestamps.json'\n",
      "✓ Saved forecasts to 'forecasts.json'\n",
      "✓ Saved stations DataFrame to 'stations.csv'\n",
      "✓ Saved sample forecast DataFrame to 'forecast_sample.csv'\n",
      "\n",
      "=== Done! ===\n",
      "Check the generated files in your current directory.\n"
     ]
    }
   ],
   "source": [
    "# DWD MOSMIX Parser - Example Jupyter Notebook\n",
    "\n",
    "# First, install required dependencies if needed:\n",
    "# !pip install lxml\n",
    "# !pip install timezonefinder  # Optional, for timezone support\n",
    "\n",
    "# Import the necessary modules\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Copy the DwdMosmixNotebook class code from the previous cell here\n",
    "# ... (include the full parser code from the previous artifact)\n",
    "\n",
    "# Example 1: Basic usage\n",
    "print(\"=== DWD MOSMIX Parser Example ===\")\n",
    "\n",
    "# Initialize the parser with your KMZ/KML file\n",
    "# Replace 'your_file.kmz' with the actual path to your DWD MOSMIX file\n",
    "file_path = \"MOSMIX_L_LATEST_01001(1).kmz\"  # or \"your_file.kml\"\n",
    "\n",
    "try:\n",
    "    parser = DwdMosmixNotebook(file_path)\n",
    "    print(f\"✓ Successfully initialized parser with file: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error initializing parser: {e}\")\n",
    "    print(\"Make sure your file path is correct and the file exists\")\n",
    "\n",
    "# Example 2: Get forecast timestamps\n",
    "print(\"\\n=== Getting Forecast Timestamps ===\")\n",
    "try:\n",
    "    timestamps = parser.get_timestamps_readable()\n",
    "    print(f\"Found {len(timestamps)} forecast timestamps\")\n",
    "    print(\"First 5 timestamps:\")\n",
    "    for i, ts in enumerate(timestamps[:5]):\n",
    "        print(f\"  {i+1}. {ts}\")\n",
    "    if len(timestamps) > 5:\n",
    "        print(f\"  ... and {len(timestamps) - 5} more\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting timestamps: {e}\")\n",
    "\n",
    "# Example 3: Get weather stations\n",
    "print(\"\\n=== Getting Weather Stations ===\")\n",
    "try:\n",
    "    stations = parser.get_stations(include_timezones=True)\n",
    "    print(f\"Found {len(stations)} weather stations\")\n",
    "    \n",
    "    # Display first few stations\n",
    "    print(\"\\nFirst 3 stations:\")\n",
    "    for i, station in enumerate(stations[:3]):\n",
    "        print(f\"  {i+1}. {station['name']} ({station['desc']})\")\n",
    "        print(f\"     Location: {station['lat']:.4f}°N, {station['lng']:.4f}°E\")\n",
    "        print(f\"     Elevation: {station['ele']:.0f}m\")\n",
    "        if station['tz']:\n",
    "            print(f\"     Timezone: {station['tz']}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error getting stations: {e}\")\n",
    "\n",
    "# Example 4: Convert stations to DataFrame for easier analysis\n",
    "print(\"\\n=== Converting Stations to DataFrame ===\")\n",
    "try:\n",
    "    stations_df = pd.DataFrame(stations)\n",
    "    print(f\"DataFrame shape: {stations_df.shape}\")\n",
    "    print(\"\\nColumn names:\", stations_df.columns.tolist())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(stations_df.head())\n",
    "    \n",
    "    # Some basic statistics\n",
    "    print(f\"\\nLatitude range: {stations_df['lat'].min():.2f}° to {stations_df['lat'].max():.2f}°\")\n",
    "    print(f\"Longitude range: {stations_df['lng'].min():.2f}° to {stations_df['lng'].max():.2f}°\")\n",
    "    print(f\"Elevation range: {stations_df['ele'].min():.0f}m to {stations_df['ele'].max():.0f}m\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating DataFrame: {e}\")\n",
    "\n",
    "# Example 5: Find stations by name\n",
    "print(\"\\n=== Finding Stations by Name ===\")\n",
    "try:\n",
    "    # Search for stations containing \"Berlin\"\n",
    "    berlin_station = parser.get_station_by_name(\"Berlin\")\n",
    "    if berlin_station:\n",
    "        print(f\"Found Berlin station: {berlin_station['name']}\")\n",
    "        print(f\"  Location: {berlin_station['lat']:.4f}°N, {berlin_station['lng']:.4f}°E\")\n",
    "        print(f\"  Station ID: {berlin_station['desc']}\")\n",
    "    else:\n",
    "        print(\"No Berlin station found\")\n",
    "        \n",
    "    # Search for stations containing \"Munich\" or \"München\"\n",
    "    munich_station = parser.get_station_by_name(\"München\")\n",
    "    if munich_station:\n",
    "        print(f\"Found Munich station: {munich_station['name']}\")\n",
    "        print(f\"  Location: {munich_station['lat']:.4f}°N, {munich_station['lng']:.4f}°E\")\n",
    "        print(f\"  Station ID: {munich_station['desc']}\")\n",
    "    else:\n",
    "        print(\"No Munich station found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error finding stations: {e}\")\n",
    "\n",
    "# Example 6: Find nearby stations\n",
    "print(\"\\n=== Finding Nearby Stations ===\")\n",
    "try:\n",
    "    # Find stations near Berlin (52.52°N, 13.41°E)\n",
    "    nearby_stations = parser.get_stations_near(52.52, 13.41, max_distance_km=100)\n",
    "    print(f\"Found {len(nearby_stations)} stations within 100km of Berlin\")\n",
    "    \n",
    "    print(\"\\nClosest 5 stations to Berlin:\")\n",
    "    for i, station in enumerate(nearby_stations[:5]):\n",
    "        print(f\"  {i+1}. {station['name']} - {station['distance_km']}km away\")\n",
    "        print(f\"     Location: {station['lat']:.4f}°N, {station['lng']:.4f}°E\")\n",
    "        print(f\"     Station ID: {station['desc']}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error finding nearby stations: {e}\")\n",
    "\n",
    "# Example 7: Get forecast data for specific stations\n",
    "print(\"\\n=== Getting Forecast Data ===\")\n",
    "try:\n",
    "    # Get forecasts for the first 3 stations\n",
    "    station_ids = [station['desc'] for station in stations[:3]]\n",
    "    forecasts = parser.get_forecasts(station_ids)\n",
    "    \n",
    "    print(f\"Retrieved forecasts for {len(forecasts)} stations\")\n",
    "    \n",
    "    # Display forecast parameters for the first station\n",
    "    first_station_id = list(forecasts.keys())[0]\n",
    "    first_station_forecast = forecasts[first_station_id]\n",
    "    \n",
    "    print(f\"\\nForecast parameters for station {first_station_id}:\")\n",
    "    for param, values in first_station_forecast.items():\n",
    "        non_null_values = [v for v in values if v is not None]\n",
    "        print(f\"  {param}: {len(values)} values ({len(non_null_values)} non-null)\")\n",
    "        if non_null_values:\n",
    "            print(f\"    Range: {min(non_null_values):.2f} to {max(non_null_values):.2f}\")\n",
    "    \n",
    "    # Example: Create a simple forecast DataFrame for one station\n",
    "    print(f\"\\n=== Creating Forecast DataFrame for {first_station_id} ===\")\n",
    "    \n",
    "    # Combine timestamps with forecast data\n",
    "    forecast_data = []\n",
    "    for i, timestamp in enumerate(timestamps):\n",
    "        row = {'timestamp': timestamp}\n",
    "        for param, values in first_station_forecast.items():\n",
    "            if i < len(values):\n",
    "                row[param] = values[i]\n",
    "        forecast_data.append(row)\n",
    "    \n",
    "    forecast_df = pd.DataFrame(forecast_data)\n",
    "    print(f\"Created DataFrame with {len(forecast_df)} rows and {len(forecast_df.columns)} columns\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(forecast_df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error getting forecasts: {e}\")\n",
    "\n",
    "# Example 8: Save data to files\n",
    "print(\"\\n=== Saving Data to Files ===\")\n",
    "try:\n",
    "    # Save stations to JSON\n",
    "    parser.save_to_json(stations, 'stations.json')\n",
    "    print(\"✓ Saved stations to 'stations.json'\")\n",
    "    \n",
    "    # Save timestamps to JSON\n",
    "    parser.save_to_json(timestamps, 'timestamps.json')\n",
    "    print(\"✓ Saved timestamps to 'timestamps.json'\")\n",
    "    \n",
    "    # Save forecasts to JSON\n",
    "    # Note: This might be a large file depending on how many stations you have\n",
    "    parser.save_to_json(forecasts, 'forecasts.json')\n",
    "    print(\"✓ Saved forecasts to 'forecasts.json'\")\n",
    "    \n",
    "    # Save stations DataFrame to CSV\n",
    "    stations_df.to_csv('stations.csv', index=False)\n",
    "    print(\"✓ Saved stations DataFrame to 'stations.csv'\")\n",
    "    \n",
    "    # Save forecast DataFrame to CSV\n",
    "    forecast_df.to_csv('forecast_sample.csv', index=False)\n",
    "    print(\"✓ Saved sample forecast DataFrame to 'forecast_sample.csv'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving files: {e}\")\n",
    "\n",
    "print(\"\\n=== Done! ===\")\n",
    "print(\"Check the generated files in your current directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "water-level",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
